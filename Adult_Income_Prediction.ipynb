{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "libraries"
      ],
      "metadata": {
        "id": "fIdrZGCown97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from scipy.stats.mstats import winsorize\n"
      ],
      "metadata": {
        "id": "1bCbJTJTwrje"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, KBinsDiscretizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        ")"
      ],
      "metadata": {
        "id": "k8VTqG3Ww1Ah"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n"
      ],
      "metadata": {
        "id": "fC8NCQ51w_BM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required libraries\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the CSV file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Read the uploaded file into a pandas DataFrame\n",
        "df = pd.read_csv(next(iter(uploaded)))\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "SJtMHPQzzsu_",
        "outputId": "29ae10f4-870a-46f5-a412-fbfa533c8b19"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6d0452df-a003-4b9d-bcc4-3bffed4bbe1d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6d0452df-a003-4b9d-bcc4-3bffed4bbe1d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving adult.csv to adult.csv\n",
            "       age     workclass  fnlwgt     education  educational-num  \\\n",
            "0       25       Private  226802          11th                7   \n",
            "1       38       Private   89814       HS-grad                9   \n",
            "2       28     Local-gov  336951    Assoc-acdm               12   \n",
            "3       44       Private  160323  Some-college               10   \n",
            "4       18             ?  103497  Some-college               10   \n",
            "...    ...           ...     ...           ...              ...   \n",
            "48837   27       Private  257302    Assoc-acdm               12   \n",
            "48838   40       Private  154374       HS-grad                9   \n",
            "48839   58       Private  151910       HS-grad                9   \n",
            "48840   22       Private  201490       HS-grad                9   \n",
            "48841   52  Self-emp-inc  287927       HS-grad                9   \n",
            "\n",
            "           marital-status         occupation relationship   race  gender  \\\n",
            "0           Never-married  Machine-op-inspct    Own-child  Black    Male   \n",
            "1      Married-civ-spouse    Farming-fishing      Husband  White    Male   \n",
            "2      Married-civ-spouse    Protective-serv      Husband  White    Male   \n",
            "3      Married-civ-spouse  Machine-op-inspct      Husband  Black    Male   \n",
            "4           Never-married                  ?    Own-child  White  Female   \n",
            "...                   ...                ...          ...    ...     ...   \n",
            "48837  Married-civ-spouse       Tech-support         Wife  White  Female   \n",
            "48838  Married-civ-spouse  Machine-op-inspct      Husband  White    Male   \n",
            "48839             Widowed       Adm-clerical    Unmarried  White  Female   \n",
            "48840       Never-married       Adm-clerical    Own-child  White    Male   \n",
            "48841  Married-civ-spouse    Exec-managerial         Wife  White  Female   \n",
            "\n",
            "       capital-gain  capital-loss  hours-per-week native-country income  \n",
            "0                 0             0              40  United-States  <=50K  \n",
            "1                 0             0              50  United-States  <=50K  \n",
            "2                 0             0              40  United-States   >50K  \n",
            "3              7688             0              40  United-States   >50K  \n",
            "4                 0             0              30  United-States  <=50K  \n",
            "...             ...           ...             ...            ...    ...  \n",
            "48837             0             0              38  United-States  <=50K  \n",
            "48838             0             0              40  United-States   >50K  \n",
            "48839             0             0              40  United-States  <=50K  \n",
            "48840             0             0              20  United-States  <=50K  \n",
            "48841         15024             0              40  United-States   >50K  \n",
            "\n",
            "[48842 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    message=\"In version 1.5 onwards, subsample=200_000 will be used by default.*\",\n",
        ")\n",
        "\n",
        "s = time.time()"
      ],
      "metadata": {
        "id": "j-Jp_MzzxC_Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    file_path = \"adult.csv\"  # Make sure both files are in same directory\n",
        "    return pd.read_csv(file_path, na_values=[\"?\"]).drop_duplicates()\n",
        "\n"
      ],
      "metadata": {
        "id": "wX4rvg4XxI5Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df):\n",
        "    # Convert all columns to string type\n",
        "    df = df.astype(str)\n",
        "    # Encode categorical data\n",
        "    le = LabelEncoder()\n",
        "    for column in df.columns:\n",
        "        df[column] = le.fit_transform(df[column])\n",
        "    return df"
      ],
      "metadata": {
        "id": "xcYPqri4xNBx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(classifiers, X_train, X_test, y_train, y_test):\n",
        "    results = []\n",
        "    for name, clf in classifiers.items():\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        results.append(\n",
        "            {\n",
        "                \"Accuracy (%)\": round(accuracy, 3),\n",
        "                \"F1 Score\": f1,\n",
        "            }\n",
        "        )\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "Y5siPj7zxTzu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data = load_data()\n",
        "\n",
        "data = preprocess_data(data)"
      ],
      "metadata": {
        "id": "-cKHw11J0-Qx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into features and target variable\n",
        "X = data.drop(\"income\", axis=1)\n",
        "y = data[\"income\"]"
      ],
      "metadata": {
        "id": "FAP3uPvk1C6n"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "7XdyOY3q1GWX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    # \"RF\": RandomForestClassifier(random_state=0),\n",
        "    \"XGB\": XGBClassifier(\n",
        "        random_state=42,\n",
        "    ),\n",
        "}"
      ],
      "metadata": {
        "id": "A6DgVA4S1KHf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate classifiers\n",
        "results = train_and_evaluate(classifiers, X_train, X_test, y_train, y_test)\n",
        "# print(\"Results for Baseline:\")\n",
        "# print(results, \"\\n\")\n",
        "# print(\n",
        "#     \"------------------------------------------------------------------------------------------------\"\n",
        "# )"
      ],
      "metadata": {
        "id": "oqCzJYVK1PJw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply winsorization to training data\n",
        "def winsorize_dataframe(df, limits):\n",
        "    df_winsorized = df.copy()\n",
        "    for column in df.columns:\n",
        "        df_winsorized[column] = winsorize(df[column], limits=limits)\n",
        "    return df_winsorized\n",
        "\n",
        "\n",
        "X_train_winsor = winsorize_dataframe(X_train, limits=[0.05, 0.05])\n"
      ],
      "metadata": {
        "id": "Fqmh-OdG1TaD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate classifiers after winsorization\n",
        "results_winsor = train_and_evaluate(\n",
        "    classifiers, X_train_winsor, X_test, y_train, y_test\n",
        ")"
      ],
      "metadata": {
        "id": "B-FchdgF1ZQd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply imputation with mean\n",
        "def impute_outliers(df, method):\n",
        "    df_imputed = df.copy()\n",
        "    for column in df.columns:\n",
        "        lower_limit = df_imputed[column].quantile(0.05)\n",
        "        upper_limit = df_imputed[column].quantile(0.95)\n",
        "        outlier_mask = (df_imputed[column] < lower_limit) | (\n",
        "            df_imputed[column] > upper_limit\n",
        "        )\n",
        "        mean_value = df_imputed[column].mean()\n",
        "        df_imputed.loc[outlier_mask, column] = mean_value.astype(df[column].dtype)\n",
        "    return df_imputed"
      ],
      "metadata": {
        "id": "nVmJ4clG1dkf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mean_imputed = impute_outliers(X_train, method=\"mean\")\n",
        "\n",
        "# Train and evaluate classifiers after imputation\n",
        "results_mean_imputed = train_and_evaluate(\n",
        "    classifiers,\n",
        "    X_train_mean_imputed,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        ")"
      ],
      "metadata": {
        "id": "bEd2k2i91jG7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply binning\n",
        "est = KBinsDiscretizer(n_bins=10, encode=\"ordinal\", strategy=\"uniform\")\n",
        "X_train_binned = est.fit_transform(X_train)\n",
        "X_test_binned = est.transform(X_test)"
      ],
      "metadata": {
        "id": "W3UlhZzZ1n8g"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate classifiers on binned data\n",
        "results_binned = train_and_evaluate(\n",
        "    classifiers, X_train_binned, X_test_binned, y_train, y_test)"
      ],
      "metadata": {
        "id": "Kxuqgofn1sWh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing values\n",
        "data = load_data()\n",
        "data_NA = data.dropna()\n",
        "data_NA_pre = preprocess_data(data_NA)\n",
        "\n",
        "# Split data into features and target variable after dropping rows with missing values\n",
        "X_dropna = data_NA_pre.drop(\"income\", axis=1)\n",
        "y_dropna = data_NA_pre[\"income\"]\n",
        "\n",
        "# Split the dataset into train and test sets again\n",
        "X_train_dropna, X_test_dropna, y_train_dropna, y_test_dropna = train_test_split(\n",
        "    X_dropna, y_dropna, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "eRK6gEY511HV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate classifiers after dropping rows with missing values\n",
        "results_dropna = train_and_evaluate(\n",
        "    classifiers,\n",
        "    X_train_dropna,\n",
        "    X_test_dropna,\n",
        "    y_train_dropna,\n",
        "    y_test_dropna,\n",
        ")\n",
        "# print(\"Results after Dropping Rows with Missing Values:\")\n",
        "# print(results_dropna, \"\\n\")\n",
        "# print(    \"------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "data_MI = load_data()\n",
        "data_MI_NA = data_MI.fillna(data_NA_pre.mean())"
      ],
      "metadata": {
        "id": "Wru0oMlR18ry"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data after imputation with mean\n",
        "data_MI_NA = preprocess_data(data_MI_NA)\n",
        "\n",
        "X_MI = data_MI_NA.drop(\"income\", axis=1)\n",
        "y_MI = data_MI_NA[\"income\"]\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "X_train_MI, X_test_MI, y_train_MI, y_test_MI = train_test_split(\n",
        "    X_MI, y_MI, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train and evaluate classifiers after imputation with mean\n",
        "results_mean_NA = train_and_evaluate(\n",
        "    classifiers,\n",
        "    X_train_MI,\n",
        "    X_test_MI,\n",
        "    y_train_MI,\n",
        "    y_test_MI,\n",
        ")"
      ],
      "metadata": {
        "id": "2AIyk7UP2C4a"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interpolation: Linear Interpolation\n",
        "data_inter = load_data()\n",
        "\n",
        "X_inter = data_inter.drop(\"income\", axis=1)\n",
        "y_inter = data_inter[\"income\"]\n",
        "\n",
        "# Convert object columns to numeric type\n",
        "X_inter_numeric = X_inter.apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "X_train_inter, X_test_inter, y_train_inter, y_test_inter = train_test_split(\n",
        "    X_inter_numeric, y_inter, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Perform linear interpolation on the data\n",
        "X_train_linear_interpolate = X_train_inter.interpolate(method=\"linear\")\n",
        "X_test_linear_interpolate = X_test_inter.interpolate(method=\"linear\")\n",
        "\n",
        "# Perform one-hot encoding on categorical variables\n",
        "X_train_encoded = pd.get_dummies(X_train_linear_interpolate)\n",
        "X_test_encoded = pd.get_dummies(X_test_linear_interpolate)\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the target variable\n",
        "y_train_encoded = label_encoder.fit_transform(y_train_inter)\n",
        "y_test_encoded = label_encoder.transform(y_test_inter)\n",
        "\n",
        "# Train and evaluate classifiers on data with one-hot encoding\n",
        "results_linear_interpolate_encoded = train_and_evaluate(\n",
        "    classifiers,\n",
        "    X_train_encoded,\n",
        "    X_test_encoded,\n",
        "    y_train_encoded,\n",
        "    y_test_encoded,\n",
        ")"
      ],
      "metadata": {
        "id": "ESucn62d2JlO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define resampling techniques\n",
        "over_sampler = RandomOverSampler(random_state=42)\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Apply resampling techniques to training data\n",
        "X_train_over, y_train_over = over_sampler.fit_resample(X_train, y_train)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers after resampling\n",
        "\n",
        "results_over = train_and_evaluate(\n",
        "    classifiers,\n",
        "    X_train_over,\n",
        "    X_test,\n",
        "    y_train_over,\n",
        "    y_test,\n",
        ")\n",
        "\n",
        "results_smote = train_and_evaluate(\n",
        "    classifiers, X_train_smote, X_test, y_train_smote, y_test\n",
        ")\n"
      ],
      "metadata": {
        "id": "WYUQEQBp2QBl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize classifiers with class weights\n",
        "classifiers_weighted = {\n",
        "    \"RF (Class Weight)\": RandomForestClassifier(class_weight=\"balanced\", random_state=0)\n",
        "}\n",
        "\n",
        "# Train and evaluate classifiers with class weights\n",
        "results_weighted = train_and_evaluate(\n",
        "    classifiers_weighted,\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        ")"
      ],
      "metadata": {
        "id": "mieAAGiS2Vi7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate all results DataFrames\n",
        "all_results = pd.concat(\n",
        "    [\n",
        "        results.assign(Preprocessing=\"Base\"),\n",
        "        results_winsor.assign(Preprocessing=\"Winsorization 5/95\"),\n",
        "        results_mean_imputed.assign(Preprocessing=\"Mean Imputation in Outliers\"),\n",
        "        results_binned.assign(Preprocessing=\"Binning in Outliers\"),\n",
        "        results_dropna.assign(Preprocessing=\"Dropping NA\"),\n",
        "        results_mean_NA.assign(Preprocessing=\"Mean Imputation in NA\"),\n",
        "        results_linear_interpolate_encoded.assign(Preprocessing=\"Linear Interpolation\"),\n",
        "        results_over.assign(Preprocessing=\"Over Sampling\"),\n",
        "        results_smote.assign(Preprocessing=\"SMOTE\"),\n",
        "        results_weighted.assign(Preprocessing=\"Class Weights\"),\n",
        "    ],\n",
        "    ignore_index=True,\n",
        ")"
      ],
      "metadata": {
        "id": "E3tvIF0D2c1Q"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reorder columns to make \"Preprocessing\" the first column\n",
        "all_results = all_results[[\"Preprocessing\", \"Accuracy (%)\", \"F1 Score\"]]\n",
        "\n",
        "e = time.time()\n",
        "\n",
        "# Export all results to a single CSV file\n",
        "all_results.to_csv(\"all_results.csv\", index=False)\n",
        "print(\"9 Strategies to handle 3 challenges usin XGBoost:\\n\\n\", all_results)\n",
        "\n",
        "# Find the row with maximum accuracy\n",
        "max_accuracy_row = all_results.loc[all_results[\"Accuracy (%)\"].idxmax()]\n",
        "\n",
        "# Print the row with maximum accuracy\n",
        "print(\"\\nMAX Accuracy:\", max_accuracy_row)\n",
        "print(\"\\nTotal time taken:\", round(e - s, 3), \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwJ6htow2g66",
        "outputId": "42dda813-592b-4bde-fab1-634e87dee904"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 Strategies to handle 3 challenges usin XGBoost:\n",
            "\n",
            "                  Preprocessing  Accuracy (%)  F1 Score\n",
            "0                         Base        87.026  0.703513\n",
            "1           Winsorization 5/95        84.864  0.655952\n",
            "2  Mean Imputation in Outliers        84.136  0.629488\n",
            "3          Binning in Outliers        85.776  0.669681\n",
            "4                  Dropping NA        86.563  0.704335\n",
            "5        Mean Imputation in NA        87.344  0.709343\n",
            "6         Linear Interpolation        84.341  0.595339\n",
            "7                Over Sampling        83.870  0.713088\n",
            "8                        SMOTE        85.991  0.700022\n",
            "9                Class Weights        85.263  0.656638\n",
            "\n",
            "MAX Accuracy: Preprocessing    Mean Imputation in NA\n",
            "Accuracy (%)                    87.344\n",
            "F1 Score                      0.709343\n",
            "Name: 5, dtype: object\n",
            "\n",
            "Total time taken: 1427.925 seconds\n"
          ]
        }
      ]
    }
  ]
}